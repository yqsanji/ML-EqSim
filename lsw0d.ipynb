{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-30T09:13:41.587419Z","iopub.execute_input":"2022-06-30T09:13:41.587839Z","iopub.status.idle":"2022-06-30T09:13:41.601362Z","shell.execute_reply.started":"2022-06-30T09:13:41.587802Z","shell.execute_reply":"2022-06-30T09:13:41.600143Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Load data\ntrain_toy_data=pd.read_csv('/kaggle/input/0dlsw/all.csv',delimiter=' ')\nselect_cols=['mu_s(imus)','mu_d(imud)','dc(idc)','t','V']\nselect_df_data=train_toy_data[select_cols]\n\nsns.pairplot(select_df_data, diag_kws={'bins': 10})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T07:28:35.237177Z","iopub.execute_input":"2022-06-30T07:28:35.237550Z","iopub.status.idle":"2022-06-30T07:29:02.745898Z","shell.execute_reply.started":"2022-06-30T07:28:35.237521Z","shell.execute_reply":"2022-06-30T07:29:02.745075Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Time-Lag : series_to_supervised()\ndef series_to_supervised(data,n_in=1,n_out=1,dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df=pd.DataFrame(data)\n    cols,names=list(),list()\n    for i in range(n_in,0,-1):\n        cols.append(df.shift(i))\n        names+=[('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    for i in range(0,n_out):\n        cols.append(df.shift(-i))\n        if i==0:\n            names+=[('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names+=[('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    agg=pd.concat(cols, axis=1)\n    agg.columns = names\n    if dropnan:\n        agg.dropna(inplace=False)\n    agg[names]=agg[names].fillna(0)\n    return agg\n\nt_lag=pd.DataFrame()\ntest_t_lag=pd.DataFrame()\nfor it in range(0,125):\n    TT=pd.read_csv('/kaggle/input/0dlsw/all.csv',delimiter=' ',skiprows=(it*5000),nrows=5000)\n    TT_lag=series_to_supervised(list(TT.iloc[:,6]),3)\n    t_lag=t_lag.append(TT_lag)\n\nprint(t_lag['var1(t-3)'])\nlag_t=np.array(t_lag[['var1(t-3)','var1(t-2)','var1(t-1)']])\nprint(np.shape(lag_t))\n\nfor it in range(0,8):\n    test_TT=pd.read_csv('/kaggle/input/testdata/test.csv',delimiter=' ',skiprows=(it*5000),nrows=5000)\n    test_TT_lag=series_to_supervised(list(test_TT.iloc[:,6]),3)\n    test_t_lag=test_t_lag.append(test_TT_lag)\n\ntest_lag_t=np.array(test_t_lag[['var1(t-3)','var1(t-2)','var1(t-1)']])\nprint(np.shape(test_lag_t))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:02:49.736482Z","iopub.execute_input":"2022-06-30T09:02:49.737026Z","iopub.status.idle":"2022-06-30T09:03:01.132359Z","shell.execute_reply.started":"2022-06-30T09:02:49.736975Z","shell.execute_reply":"2022-06-30T09:03:01.131204Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# Random Forest Regression\n# Train data\nX_train=np.array(train_toy_data[['mu_s(imus)','mu_d(imud)','dc(idc)','t']])\nX_train=np.hstack((X_train,lag_t))\nprint(np.shape(X_train)) # 625000 = 5000 (t) * 5 (mu_s) * 5 (mu_d) * 5(dc)\n# Train target\ny_train=np.array(train_toy_data[['V']]).ravel()\nprint(np.shape(y_train))\n\n# Test data\ntest_toy_data=pd.read_csv('/kaggle/input/testdata/test.csv',delimiter=' ')\nX_test=np.array(test_toy_data[['mu_s(imus)','mu_d(imud)','dc(idc)','t']])\nX_test=np.hstack((X_test,test_lag_t))\nprint(np.shape(X_test)) # 40000 = 5000 (t) * 2 (mu_s) * 2 (mu_d) * 2 (dc)\ny_test=np.array(test_toy_data[['V']]).ravel()\nprint(np.shape(y_test))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:03:22.736933Z","iopub.execute_input":"2022-06-30T09:03:22.738073Z","iopub.status.idle":"2022-06-30T09:03:22.806791Z","shell.execute_reply.started":"2022-06-30T09:03:22.738029Z","shell.execute_reply":"2022-06-30T09:03:22.805495Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# RF model\nrfmodel=RandomForestRegressor()\nrfmodel.fit(X_train,y_train)\n\nscore=rfmodel.score(X_train,y_train)\nprint(\"R-squared:\", score)\n\ny_pred=rfmodel.predict(X_test)\nmse=mean_squared_error(y_test,y_pred)\nprint(\"MSE: \", mse)\nprint(\"RMSE: \", mse*(1/2.0))\n\n\n# Change param: https://www.cnblogs.com/pinard/p/6160412.html (手动调参）\n#estimators = np.arange(10, 200, 10)\n#scores = []\n#for n in estimators:\n    #rfmodel.set_params(n_estimators=n)\n    #rfmodel.fit(X_train, y_train)\n    #scores.append(rfmodel.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:14:03.538576Z","iopub.execute_input":"2022-06-30T09:14:03.538997Z","iopub.status.idle":"2022-06-30T09:15:59.037716Z","shell.execute_reply.started":"2022-06-30T09:14:03.538959Z","shell.execute_reply":"2022-06-30T09:15:59.036157Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(X_test[:5000,3],y_test[:5000],label='groundtruth_1',linewidth=1)\nplt.plot(X_test[:5000,3],y_pred[:5000],label='predicted_1',linewidth=2)\nplt.plot(X_test[15001:20000,3],y_test[15001:20000],label='groundtruth_2',linewidth=1)\nplt.plot(X_test[15001:20000,3],y_pred[15001:20000],label='predicted_2',linewidth=2)\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:35:20.495956Z","iopub.execute_input":"2022-06-30T09:35:20.496395Z","iopub.status.idle":"2022-06-30T09:35:20.738521Z","shell.execute_reply.started":"2022-06-30T09:35:20.496360Z","shell.execute_reply":"2022-06-30T09:35:20.737158Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# Tensorflow for multifeatures doing Linear Regression\n# https://blog.csdn.net/zhangchao19890805/article/details/82422333\n\n# But HARD for Linear Regression to predict multi-input-output \n# Instead using LSTM (Long Short-Term Memory) -- RNN (Recurrence Neural Network) in Tensorflow\n# https://cloud.tencent.com/developer/article/1041442\n","metadata":{},"execution_count":null,"outputs":[]}]}